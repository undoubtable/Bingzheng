{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24d1a05",
   "metadata": {},
   "source": [
    "# 神经符号 AI 示例：Transformer + gplearn (符号回归/分类)\n",
    "\n",
    "本 notebook 演示如何将神经网络（一个非常小的 Transformer 风格编码器）与符号学习（使用 gplearn 的 SymbolicClassifier）结合，构建一个简单的可解释分类流程：\\n\n",
    "1) 使用 sklearn 的 digits 数据集；\\n\n",
    "2) 训练一个小型 Transformer（PyTorch）用于特征提取（得到每张图像的嵌入向量）；\\n\n",
    "3) 在嵌入向量上训练 gplearn 的 SymbolicClassifier，得到一个可读的符号表达式；\\n\n",
    "4) 比较神经模型与符号模型的性能，并展示符号表达式。\\n\n",
    "\n",
    "依赖库：torch, torchvision, scikit-learn, gplearn, numpy。为简洁起见，模型较小并只训练少量 epoch，适合在 CPU 上运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41401cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: gplearn in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\.conda\\envs\\xzz\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 如果尚未安装依赖，请先运行（取消注释并执行）：\n",
    "%pip install torch torchvision scikit-learn gplearn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b971b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\.conda\\envs\\XZZ\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8 loss=0.3589 acc=0.8984\n",
      "Epoch 2/8 loss=0.3314 acc=0.8984\n",
      "Epoch 2/8 loss=0.3314 acc=0.8984\n",
      "Epoch 3/8 loss=0.3293 acc=0.8984\n",
      "Epoch 3/8 loss=0.3293 acc=0.8984\n",
      "Epoch 4/8 loss=0.3297 acc=0.8984\n",
      "Epoch 4/8 loss=0.3297 acc=0.8984\n",
      "Epoch 5/8 loss=0.3303 acc=0.8984\n",
      "Epoch 5/8 loss=0.3303 acc=0.8984\n",
      "Epoch 6/8 loss=0.3275 acc=0.8984\n",
      "Epoch 6/8 loss=0.3275 acc=0.8984\n",
      "Epoch 7/8 loss=0.3254 acc=0.8984\n",
      "Epoch 7/8 loss=0.3254 acc=0.8984\n",
      "Epoch 8/8 loss=0.3228 acc=0.8984\n",
      "Embeddings shapes: (1437, 16) (360, 16)\n",
      "y_test distribution: [323  37]\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "Epoch 8/8 loss=0.3228 acc=0.8984\n",
      "Embeddings shapes: (1437, 16) (360, 16)\n",
      "y_test distribution: [323  37]\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    22.65          2.30855       15         0.317483         0.313259      3.70s\n",
      "gplearn fit completed successfully\n",
      "Learned program:\n",
      "sub(add(add(X1, X6), sub(X10, X6)), sub(add(X12, 0.866), mul(X10, X0)))\n",
      "Symbolic classifier accuracy: 0.8972222222222223\n",
      "Symbolic expression:\n",
      "sub(add(add(X1, X6), sub(X10, X6)), sub(add(X12, 0.866), mul(X10, X0)))\n",
      "y_test distribution: [323  37]\n",
      "y_pred_sym unique counts: {0: 360}\n",
      "Confusion matrix (symbolic):\n",
      "[[323   0]\n",
      " [ 37   0]]\n",
      "Logistic regression accuracy: 0.8972222222222223\n",
      "Classification report (symbolic):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       323\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.90       360\n",
      "   macro avg       0.45      0.50      0.47       360\n",
      "weighted avg       0.81      0.90      0.85       360\n",
      "\n",
      "   0    22.65          2.30855       15         0.317483         0.313259      3.70s\n",
      "gplearn fit completed successfully\n",
      "Learned program:\n",
      "sub(add(add(X1, X6), sub(X10, X6)), sub(add(X12, 0.866), mul(X10, X0)))\n",
      "Symbolic classifier accuracy: 0.8972222222222223\n",
      "Symbolic expression:\n",
      "sub(add(add(X1, X6), sub(X10, X6)), sub(add(X12, 0.866), mul(X10, X0)))\n",
      "y_test distribution: [323  37]\n",
      "y_pred_sym unique counts: {0: 360}\n",
      "Confusion matrix (symbolic):\n",
      "[[323   0]\n",
      " [ 37   0]]\n",
      "Logistic regression accuracy: 0.8972222222222223\n",
      "Classification report (symbolic):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       323\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.90       360\n",
      "   macro avg       0.45      0.50      0.47       360\n",
      "weighted avg       0.81      0.90      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# gplearn 用于符号学习（导入但延后 fit）\n",
    "from gplearn.genetic import SymbolicClassifier\n",
    "\n",
    "# 1. 加载数据（digits）\n",
    "digits = load_digits()\n",
    "X = digits.images  # shape (n_samples, 8, 8)\n",
    "y = digits.target\n",
    "\n",
    "# 为了示例，把问题简化为二分类：是否为数字 3\n",
    "y_bin = (y == 3).astype(int)\n",
    "\n",
    "# 扁平化图像作为 transformer 的输入序列（将 8x8 拆为 64 tokens，每 token 为像素值）\n",
    "n_samples = X.shape[0]\n",
    "X_flat = X.reshape(n_samples, -1)  # (n_samples, 64)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_flat = scaler.fit_transform(X_flat)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n",
    "\n",
    "# 将数据变为 PyTorch 需要的形状： (batch, seq_len, feature). 我们把每个像素看作 1-d token => feature_dim=1, seq_len=64\n",
    "def to_torch_dataset(X, y):\n",
    "    X_t = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
    "    y_t = torch.tensor(y, dtype=torch.long)\n",
    "    return TensorDataset(X_t, y_t)\n",
    "\n",
    "train_ds = to_torch_dataset(X_train, y_train)\n",
    "test_ds = to_torch_dataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "# 2. 定义一个非常小的 Transformer 编码器，用来把序列映射为固定长度嵌入\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=64, d_model=32, nhead=4, num_layers=1, emb_dim=16):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(1, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=64, dropout=0.1, activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(d_model, emb_dim)\n",
    "        # 最后用于直接分类的头（可选，用于比较）\n",
    "        self.classifier = nn.Linear(emb_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, 1) -> transformer expects (seq_len, batch, d_model)\n",
    "        b, s, _ = x.shape\n",
    "        x = self.input_proj(x)  # (b, s, d_model)\n",
    "        x = x.permute(1, 0, 2)  # (s, b, d_model)\n",
    "        x = self.transformer(x)  # (s, b, d_model)\n",
    "        x = x.permute(1, 2, 0)  # (b, d_model, s) for pooling\n",
    "        x = self.pool(x).squeeze(-1)  # (b, d_model)\n",
    "        emb = self.fc(x)  # (b, emb_dim)\n",
    "        logits = self.classifier(emb)\n",
    "        return logits, emb\n",
    "\n",
    "# 训练模型（少量 epoch）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TinyTransformer().to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 8\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits, _ = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    # 评估训练集上的准确率作为进度指示\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            logits, _ = model(xb)\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy().tolist())\n",
    "            trues.extend(yb.numpy().tolist())\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs} loss={avg_loss:.4f} acc={acc:.4f}')\n",
    "\n",
    "# 在测试集上提取嵌入\n",
    "model.eval()\n",
    "embs_train = []\n",
    "embs_test = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in DataLoader(to_torch_dataset(X_train, y_train), batch_size=128):\n",
    "        xb = xb.to(device)\n",
    "        _, emb = model(xb)\n",
    "        embs_train.append(emb.cpu().numpy())\n",
    "        y_train_list.append(yb.numpy())\n",
    "    for xb, yb in DataLoader(to_torch_dataset(X_test, y_test), batch_size=128):\n",
    "        xb = xb.to(device)\n",
    "        _, emb = model(xb)\n",
    "        embs_test.append(emb.cpu().numpy())\n",
    "        y_test_list.append(yb.numpy())\n",
    "embs_train = np.vstack(embs_train)\n",
    "embs_test = np.vstack(embs_test)\n",
    "y_train_arr = np.concatenate(y_train_list)\n",
    "y_test_arr = np.concatenate(y_test_list)\n",
    "\n",
    "print('Embeddings shapes:', embs_train.shape, embs_test.shape)\n",
    "print('y_test distribution:', np.bincount(y_test_arr))\n",
    "\n",
    "# 现在用 gplearn 的 SymbolicClassifier 在嵌入上学习一个符号分类器\n",
    "# 注意：gplearn 在 CPU 上执行，输入维度不宜过大。这里 emb_dim=16，样本少，适合示例。\n",
    "# 为避免 NotFittedError，我们在 fit 时加入异常捕获并输出诊断信息。\n",
    "\n",
    "# 兼容性补丁（若需要）：有些环境中 gplearn 的 SymbolicClassifier 可能缺少 sklearn 的 _validate_data 方法\n",
    "try:\n",
    "    getattr(SymbolicClassifier, '_validate_data')\n",
    "    need_patch = False\n",
    "except Exception:\n",
    "    need_patch = True\n",
    "\n",
    "if need_patch:\n",
    "    from sklearn.utils.validation import check_array, check_X_y\n",
    "    def _validate_data(self, X, y=None, accept_sparse=False, reset=True, ensure_2d=True,\n",
    "                       allow_nd=False, multi_output=False, ensure_min_samples=1,\n",
    "                       ensure_min_features=1, y_numeric=False, estimator_name=None):\n",
    "        if y is None:\n",
    "            X_checked = check_array(X, accept_sparse=accept_sparse, ensure_2d=ensure_2d,\n",
    "                                    allow_nd=allow_nd)\n",
    "            return X_checked\n",
    "        X_checked, y_checked = check_X_y(X, y, accept_sparse=accept_sparse, ensure_2d=ensure_2d,\n",
    "                                         multi_output=multi_output, y_numeric=y_numeric)\n",
    "        return X_checked, y_checked\n",
    "    setattr(SymbolicClassifier, '_validate_data', _validate_data)\n",
    "\n",
    "# 构建并拟合 SymbolicClassifier（在 try/except 中，以便捕获错误）\n",
    "sym_clf = SymbolicClassifier(population_size=500, generations=20, stopping_criteria=0.95, p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05, p_point_mutation=0.1, max_samples=0.9, verbose=1, random_state=42, parsimony_coefficient=0.001)\n",
    "fit_exception = None\n",
    "try:\n",
    "    sym_clf.fit(embs_train, y_train_arr)\n",
    "    # 有些 sklearn/gplearn 组合不会自动设置 n_features_in_，手动补齐以兼容 predict\n",
    "    if not hasattr(sym_clf, 'n_features_in_'):\n",
    "        try:\n",
    "            sym_clf.n_features_in_ = embs_train.shape[1]\n",
    "        except Exception:\n",
    "            pass\n",
    "    print('gplearn fit completed successfully')\n",
    "    try:\n",
    "        print('Learned program:')\n",
    "        print(sym_clf._program)\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    fit_exception = e\n",
    "    print('gplearn fit failed with exception:', e)\n",
    "\n",
    "# 用符号模型预测并评估（只有在 fit 成功时才执行）\n",
    "if fit_exception is None:\n",
    "    try:\n",
    "        # 若 predict 前仍缺少 n_features_in_，再补一次\n",
    "        if not hasattr(sym_clf, 'n_features_in_'):\n",
    "            try:\n",
    "                sym_clf.n_features_in_ = embs_train.shape[1]\n",
    "            except Exception:\n",
    "                pass\n",
    "        y_pred_sym = sym_clf.predict(embs_test)\n",
    "        print('Symbolic classifier accuracy:', accuracy_score(y_test_arr, y_pred_sym))\n",
    "        print('Symbolic expression:')\n",
    "        print(sym_clf._program)\n",
    "\n",
    "        # 诊断：查看符号预测分布与混淆矩阵，避免 UndefinedMetricWarning\n",
    "        print('y_test distribution:', np.bincount(y_test_arr))\n",
    "        try:\n",
    "            unique, counts = np.unique(y_pred_sym, return_counts=True)\n",
    "            print('y_pred_sym unique counts:', dict(zip(unique.tolist(), counts.tolist())))\n",
    "        except Exception:\n",
    "            print('Could not compute y_pred_sym distribution')\n",
    "        print('Confusion matrix (symbolic):')\n",
    "        try:\n",
    "            print(confusion_matrix(y_test_arr, y_pred_sym))\n",
    "        except Exception as e:\n",
    "            print('Could not compute confusion matrix:', e)\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print('Prediction with symbolic classifier failed:', e)\n",
    "else:\n",
    "    print('Skipping symbolic prediction because fit failed')\n",
    "\n",
    "# 作为对照，直接在嵌入上训练一个简单 sklearn 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(embs_train, y_train_arr)\n",
    "y_pred_lr = lr.predict(embs_test)\n",
    "print('Logistic regression accuracy:', accuracy_score(y_test_arr, y_pred_lr))\n",
    "\n",
    "# 最后展示分类报告（符号分类器使用 zero_division=0 以抑制 UndefinedMetricWarning）\n",
    "if fit_exception is None and 'y_pred_sym' in locals():\n",
    "    print('Classification report (symbolic):')\n",
    "    print(classification_report(y_test_arr, y_pred_sym, zero_division=0))\n",
    "elif fit_exception is None:\n",
    "    print('Symbolic classifier did not produce predictions')\n",
    "else:\n",
    "    print('No symbolic classification report because fit failed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
